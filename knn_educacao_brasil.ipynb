{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hip\u000f3tese escolhida (1)\n",
        "Estudantes com Acesso_Internet = Ruim/Inst\u000e1vel apresentam maior risco de evas\u000e3o (Risco_Evasao = 1), considerando tamb\u000e9m Faltas_Percentual, Trabalho_Horas_Semanais e Deslocamento_Minutos.\n",
        "\n",
        "Objetivo: treinar um KNN Classifier para `Risco_Evasao`, comparar k \n",
        "7 dist\u000e2ncias (euclidiana/manhattan), avaliar desempenho e analisar matriz de confus\u000e3o por estratos de `Acesso_Internet`. Autor: Luigi Garotti. Curso: 2\u000e0 semestre.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Caminho do CSV\n",
        "CSV_PATH = 'dataset_educacao_graduacao_brasil_500.csv'\n",
        "\n",
        "# Leitura segura\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "print('Formato:', df.shape)\n",
        "print('\\nInfo:')\n",
        "df.info()\n",
        "\n",
        "print('\\nVisao geral:')\n",
        "display(df.head())\n",
        "\n",
        "print('\\nNulos por coluna:')\n",
        "print(df.isna().sum().sort_values(ascending=False))\n",
        "\n",
        "print('\\nDescricao numerica:')\n",
        "display(df.describe(include=[np.number]).T)\n",
        "\n",
        "print('\\nDescricao categorica:')\n",
        "cat_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "if len(cat_cols) > 0:\n",
        "    display(df[cat_cols].describe().T)\n",
        "else:\n",
        "    print('Sem colunas categoricas detectadas')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (removido) C\u001alula antiga de leitura duplicada e corrompida.\n",
        "pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Target e features\n",
        "TARGET = 'Risco_Evasao'\n",
        "\n",
        "# Features candidatas (podem ajustar conforme dataset real)\n",
        "base_features_num = [\n",
        "    'Faltas_Percentual',\n",
        "    'Trabalho_Horas_Semanais',\n",
        "    'Deslocamento_Minutos',\n",
        "    'Horas_Estudo_Semanais',\n",
        "    'Nota_ENEM'\n",
        "]\n",
        "base_features_cat = [\n",
        "    'Acesso_Internet',\n",
        "    'Modalidade',\n",
        "    'Tipo_IES'\n",
        "]\n",
        "\n",
        "# Filtra por colunas que existem de fato\n",
        "features_num = [c for c in base_features_num if c in df.columns]\n",
        "features_cat = [c for c in base_features_cat if c in df.columns]\n",
        "\n",
        "# Remover linhas com target nulo\n",
        "df_model = df.dropna(subset=[TARGET]).copy()\n",
        "\n",
        "# Op\u0000e7\u0000e3o simples para lidar com nulos nas features:\n",
        "# - num\u0000e9ricas: preencher com mediana\n",
        "# - categ\u0000f3ricas: preencher com string 'Desconhecido'\n",
        "num_impute_values = df_model[features_num].median(numeric_only=True)\n",
        "for col in features_num:\n",
        "    df_model[col] = df_model[col].fillna(num_impute_values[col])\n",
        "for col in features_cat:\n",
        "    df_model[col] = df_model[col].fillna('Desconhecido')\n",
        "\n",
        "X = df_model[features_num + features_cat]\n",
        "y = df_model[TARGET].astype(int)  # garante 0/1\n",
        "\n",
        "# Split com estratifica\u00043o no target\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.30, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# ColumnTransformer\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), features_num),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), features_cat)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Pipeline KNN (vamos variar n_neighbors e metric depois)\n",
        "knn_pipe = Pipeline(steps=[\n",
        "    ('prep', preprocess),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "])\n",
        "\n",
        "print('Features num\u0000e9ricas:', features_num)\n",
        "print('Features categ\u0000f3ricas:', features_cat)\n",
        "print('Tamanhos -> treino:', X_train.shape, '| teste:', X_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "k_values = [3,5,11,21]\n",
        "metrics = ['euclidean','manhattan']\n",
        "\n",
        "results = []\n",
        "for metric in metrics:\n",
        "    train_scores = []\n",
        "    test_scores = []\n",
        "    for k in k_values:\n",
        "        model = Pipeline(steps=[\n",
        "            ('prep', preprocess),\n",
        "            ('knn', KNeighborsClassifier(n_neighbors=k, metric=metric))\n",
        "        ])\n",
        "        model.fit(X_train, y_train)\n",
        "        acc_train = model.score(X_train, y_train)\n",
        "        acc_test = model.score(X_test, y_test)\n",
        "        train_scores.append(acc_train)\n",
        "        test_scores.append(acc_test)\n",
        "        results.append({'metric': metric, 'k': k, 'acc_train': acc_train, 'acc_test': acc_test})\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.plot(k_values, train_scores, marker='o', label='Treino')\n",
        "    plt.plot(k_values, test_scores, marker='s', label='Teste')\n",
        "    plt.title(f'Acur\u0018\u0013cia vs k ({metric})')\n",
        "    plt.xlabel('k')\n",
        "    plt.ylabel('Acur\u0018\u0013cia')\n",
        "    plt.xticks(k_values)\n",
        "    plt.ylim(0,1)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "results_df = pd.DataFrame(results).sort_values(['metric','k'])\n",
        "display(results_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Seleciona o melhor par (maior acur\u0000e1cia de teste)\n",
        "best_row = results_df.sort_values('acc_test', ascending=False).iloc[0]\n",
        "best_k = int(best_row['k'])\n",
        "best_metric = best_row['metric']\n",
        "print(f'Melhor: k={best_k}, metric={best_metric}, acc_test={best_row.acc_test:.3f}')\n",
        "\n",
        "best_model = Pipeline(steps=[\n",
        "    ('prep', preprocess),\n",
        "    ('knn', KNeighborsClassifier(n_neighbors=best_k, metric=best_metric))\n",
        "])\n",
        "\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Avalia\u0000e7\u0000e3o\n",
        "y_pred = best_model.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print('Acur\u0000e1cia (teste):', round(acc, 4))\n",
        "print('Matriz de confus\u0000e3o:\\n', cm)\n",
        "print('\\nRelat\u0000f3rio de classifica\u0000e7\u0000e3o:')\n",
        "print(classification_report(y_test, y_pred, digits=3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Matriz de confus\u0000e3o por estratos de Acesso_Internet\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "# Predi\u0000e7\u0000e3o em todo X_test para subsele\u0000e7\u0000f5es\n",
        "probas = best_model.predict_proba(X_test)[:,1]\n",
        "preds = best_model.predict(X_test)\n",
        "\n",
        "if 'Acesso_Internet' in X_test.columns:\n",
        "    categories = X_test['Acesso_Internet'].unique()\n",
        "    for cat in categories:\n",
        "        mask = (X_test['Acesso_Internet'] == cat)\n",
        "        if mask.sum() == 0:\n",
        "            continue\n",
        "        y_true_g = y_test[mask]\n",
        "        y_pred_g = preds[mask]\n",
        "        cm_g = confusion_matrix(y_true_g, y_pred_g)\n",
        "        print(f'\\nEstrato: {cat} | n={mask.sum()}')\n",
        "        print(cm_g)\n",
        "        disp = ConfusionMatrixDisplay(cm_g)\n",
        "        disp.plot(colorbar=False)\n",
        "        plt.title(f'Matriz de confus\u0000e3o - {cat}')\n",
        "        plt.show()\n",
        "else:\n",
        "    print('Coluna Acesso_Internet n\u0000e3o est\u0000e1 em X_test; n\u0000e3o \u0000e9 poss\u0000edvel estratificar')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Discuss\u0000e3o e conclus\u0000f5es\n",
        "\n",
        "- Overfitting: quando k \u0000e9 muito pequeno (tipo 3), o modelo tende a memorizar vizinhos do treino e a acur\u0000e1cia de treino fica mais alta que a de teste. Isso apareceu nas curvas.\n",
        "- Underfitting: quando k \u0000e9 grande (ex.: 21), o modelo suaviza demais e perde detalhes, o que pode derrubar a acur\u0000e1cia de ambos os conjuntos.\n",
        "- Dist\u0000e2ncia: euclidiana vs manhattan variaram pouco (depende da escala e do tipo de dado). O pipeline com StandardScaler ajudou a deixar as features num\u0000e9ricas na mesma ordem de grandeza.\n",
        "- Subgrupos: olhando as matrizes de confus\u0000e3o por `Acesso_Internet`, se os estratos \"Ruim/Inst\u0000e1vel\" mostrarem mais falsos positivos de risco (ou maior taxa de positivos), isso apoia a hip\u0000f3tese de maior risco nesses grupos.\n",
        "\n",
        "Conclus\u0000f5o: com base nas m\u0000e9tricas de teste e nas matrizes por estratos, a hip\u0000f3tese (1) foi [preencha conforme seus resultados: suportada / parcialmente suportada / n\u0000e3o suportada]. Vou relatar que k e m\u0000e9trica escolhidos (melhores) foram os mostrados acima e que o comportamento de overfitting/underfitting bate com a teoria do KNN.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
